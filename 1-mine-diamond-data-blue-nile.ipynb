{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Mining Diamond Data - Blue Nile®\n",
    "\n",
    "## (a) Introduction\n",
    "In this series of notebooks we are mining diamond data from merchants on the web, and subsequently using Machine Learning to be able to predict the price of a diamond. Diamond merchants often display data on the diamonds they are selling so people can peruse them and make a purchase online. They'll also usually have a comparison element with lots of features (the 5 C's etc.). Really though, if you're anything like me (a noob jeweller), how can you tell how the diamond is priced based on these features? I guess you'd have to take the merchants' word on it... \n",
    "\n",
    "What we need is data, and a regression algorithm looking at price. This notebook is the first in the series, and in it we'll tackle scraping Blue Nile® data from [their website](https://www.bluenile.com/uk/diamond-search) (soz Blue Nile... but thx for the data). \n",
    "\n",
    "In all seriousness, this data is the property of Blue Nile®, so please be respectful. I try and stick to web scraping best practises in these scripts, so if you are going to use it, please keep these in. They mostly revolve around slowing the functions down, which I realise may be frustrating, but let's keep to the code people.\n",
    "\n",
    "We'll start by importing our packages and defining a couple of functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Import packages / define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = [12, 7] # Change default fig size\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "import itertools\n",
    "import time # To help slow our functions down and time them\n",
    "import random # To assign random floats to breaks, hiding predictable patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define some useful functions that we'll be utilising a lot in the notebook. The last two functions are essential to working with HTML data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pause_random(start=0.3, stop=2):\n",
    "    \"\"\"\n",
    "    Pause the function for a random amount of time between the two integers entered.\n",
    "    \"\"\"\n",
    "    time.sleep(random.uniform(start, stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_content(page_link):\n",
    "    \"\"\"\n",
    "    Scrape the targeted HTML and store as a bs object\n",
    "    \"\"\"\n",
    "    page_response = requests.get(page_link, timeout=5)\n",
    "    page_content = BeautifulSoup(page_response.content)\n",
    "    return(page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "    \"\"\"\n",
    "    Remove HTML tags from string.\n",
    "    \"\"\"\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return(cleantext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Prepare Blue Nile® dataset\n",
    "\n",
    "In this section we create a function to prepare the Blue Nile table, and do some intial exploration to help our final crawler save time.\n",
    "For reference, I denote Blue Nile® as `bn` for short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For conciseness, Blue Nile we will denote as 'bn'\n",
    "bn_link = 'https://www.bluenile.com/uk/diamond-search'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start web driver\n",
    "browser = webdriver.Chrome('C:/Users/Edward Sims/Downloads/chromedriver.exe')\n",
    "browser.get(bn_link)\n",
    "pause_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"three-sixty-filter-5455\"]\"}\n  (Session info: chrome=79.0.3945.88)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-17b561ba4bfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'three-sixty-filter-5455'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_id\u001b[1;34m(self, id_)\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'foo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \"\"\"\n\u001b[1;32m--> 360\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    976\u001b[0m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0;32m    977\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m             'value': value})['value']\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"three-sixty-filter-5455\"]\"}\n  (Session info: chrome=79.0.3945.88)\n"
     ]
    }
   ],
   "source": [
    "browser.find_element_by_id('three-sixty-filter-5455')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_bn_table(link):\n",
    "    \"\"\"\n",
    "    Opens webdriver and prepares the table for scraping.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Continue past the cookie notice if it exists\n",
    "    try:\n",
    "        cookie_continue = browser.find_element_by_xpath('/html/body/div[1]/button[3]')\n",
    "        cookie_continue.click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # If the 360 view option is checked, uncheck it\n",
    "    view_checkbox_status = browser.find_element_by_xpath('/html/body/div[1]/main/div/div/div/div/section[1]/div[1]/div[2]/div[3]/div[4]/div[2]/div/div/input')\n",
    "    view_checkbox_status = str(view_checkbox_status.get_attribute('innerHTML'))\n",
    "    if 'checked' in view_checkbox_status:\n",
    "        view_checkbox = browser.find_element_by_class_name('bn-checkbox')\n",
    "        view_checkbox.click()\n",
    "        pause_random()\n",
    "\n",
    "    # If astor option is checked, uncheck it\n",
    "    astor_checkbox_status = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[5]/div[2]/div/div/div[1]/div/div')\n",
    "    astor_checkbox_status = str(astor_checkbox_status.get_attribute('innerHTML'))\n",
    "    if 'checked' in astor_checkbox_status:\n",
    "        astor_checkbox = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[5]/div[2]/div/div')\n",
    "        astor_checkbox.click()\n",
    "        pause_random()\n",
    "        \n",
    "    # If more filters is unselected, select it    \n",
    "    filter_status = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[13]/span')\n",
    "    filter_status = str(filter_status.get_attribute('innerHTML'))\n",
    "    if 'More' in filter_status:\n",
    "        more_filters = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[13]')\n",
    "        more_filters.click()\n",
    "    \n",
    "    # Add extra options if they are not already added\n",
    "    polish_add = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[12]/div[1]/div[1]/div/div')\n",
    "    symmetry_add = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[12]/div[2]/div[1]/div/div')\n",
    "    fluorescence_add = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[12]/div[3]/div[1]/div/div')\n",
    "    depth_add = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[12]/div[4]/div[1]/div/div')\n",
    "    table_add = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[12]/div[5]/div[1]/div/div')\n",
    "    lw_add = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[12]/div[6]/div[1]/div/div')\n",
    "    \n",
    "    feature_add_all = [polish_add, symmetry_add, fluorescence_add, depth_add, table_add, lw_add]\n",
    "    for feature_add in feature_add_all:\n",
    "        if 'toggled' not in str(feature_add.get_attribute('outerHTML')):\n",
    "            feature_add.click()\n",
    "            pause_random()\n",
    "            \n",
    "    culet_add = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[12]/div[8]/div[2]/button')\n",
    "    if 'active' not in str(culet_add.get_attribute('outerHTML')):\n",
    "        culet_add.click()\n",
    "        pause_random()\n",
    "    \n",
    "    # Add in all types of shape\n",
    "    round_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[1]/div[3]')\n",
    "    princess_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[2]/div[3]')\n",
    "    emerald_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[3]/div[3]')\n",
    "    asscher_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[4]/div[3]')\n",
    "    cushion_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[5]/div[3]')\n",
    "    marquise_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[6]/div[3]')\n",
    "    radiant_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[7]/div[3]')\n",
    "    oval_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[8]/div[3]')\n",
    "    pear_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[9]/div[3]')\n",
    "    heart_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[10]/div[3]')\n",
    "    \n",
    "    shape_details_all = [round_details, princess_details, emerald_details, asscher_details, cushion_details, \n",
    "                         marquise_details, radiant_details, oval_details, pear_details, heart_details]\n",
    "    \n",
    "    for shape_details in shape_details_all:\n",
    "        if 'selected' not in str(shape_details.get_attribute('outerHTML')):\n",
    "            shape_details.click()\n",
    "            pause_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[1]/main/div/div/div/div/section[1]/div[1]/div[2]/div[3]/div[4]/div[2]/div/div/input\"}\n  (Session info: chrome=79.0.3945.88)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-693d0a1e039a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Open and prepare the bn table for scraping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprep_bn_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbn_link\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-c83401d695cf>\u001b[0m in \u001b[0;36mprep_bn_table\u001b[1;34m(link)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# If the 360 view option is checked, uncheck it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mview_checkbox_status\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/html/body/div[1]/main/div/div/div/div/section[1]/div[1]/div[2]/div[3]/div[4]/div[2]/div/div/input'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mview_checkbox_status\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mview_checkbox_status\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'innerHTML'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'checked'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mview_checkbox_status\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//div/td[1]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \"\"\"\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    976\u001b[0m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0;32m    977\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m             'value': value})['value']\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[1]/main/div/div/div/div/section[1]/div[1]/div[2]/div[3]/div[4]/div[2]/div/div/input\"}\n  (Session info: chrome=79.0.3945.88)\n"
     ]
    }
   ],
   "source": [
    "# Open and prepare the bn table for scraping\n",
    "prep_bn_table(bn_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) Scrape the data\n",
    "The difficulty with scraping the table is that a maximum of 1,000 results are displayed. And the prices of diamonds are hugely skewed around the £600-£2,000 price range. \n",
    "\n",
    "So we've arrived at our first major problem: \n",
    " - If we increment our price by static small amounts, it'll take weeks (umm no thanks).\n",
    " - If we increment them by static large amounts, we'll miss out loads of data from the price ranges with high frequencies.\n",
    "\n",
    "My solution below follows this method:\n",
    " 1. Retrieve the headers for our table\n",
    " 2. Create an initial price interval\n",
    " 3. Check the number of results displayed.\n",
    " 4. If more than 999, make an estimate on the sub intervals that will approximately yield 999 or less results. Scrape the table in each sub interval.\n",
    " 5. If under 999, scrape the table.\n",
    " 6. Tracking the cumulative number of results, once there are less than 999 results left, skip to the maximum price and scrape the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bn_data():\n",
    "    \"\"\"\n",
    "    Loops through all the price values, scrapes the results and stores\n",
    "    it into a dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_num_results():\n",
    "        \"\"\"\n",
    "        Scrapes the number of results shown in the price range.    \n",
    "        \"\"\"\n",
    "        results_path = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[2]/div[4]/button[1]/span[2]')\n",
    "        # Scrape HTML and clean\n",
    "        results_val = cleanhtml(str(BeautifulSoup(results_path.get_attribute('innerHTML'))))\n",
    "        # Strip  punctuation, and convert to integer\n",
    "        results_val = int(re.sub(r'[^\\w\\s]','', results_val))\n",
    "        return(results_val)\n",
    "    \n",
    "    start = time.time()\n",
    "    bn_headers = []\n",
    "    # Isolate the table headers HTML\n",
    "    headers_data = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/section/div/div/div[1]/div')\n",
    "    headers_html = BeautifulSoup(headers_data.get_attribute('innerHTML'))\n",
    "    \n",
    "    # Get the header values\n",
    "    for div in headers_html.find_all('div'):\n",
    "        for header in div.find_all('span'):\n",
    "            bn_headers.append(cleanhtml(str(header)))\n",
    "    bn_headers = list(filter(('').__ne__, bn_headers))\n",
    "    bn_headers.remove('Compare')\n",
    "    # Create a dataframe with our new headers\n",
    "    bn_df = pd.DataFrame(columns = bn_headers)  \n",
    "    \n",
    "    # Min and max price locations\n",
    "    min_price_box = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[7]/div[2]/div/div[1]/input[1]')\n",
    "    max_price_box = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[7]/div[2]/div/div[1]/input[2]')\n",
    "    \n",
    "    # Assign default interval value\n",
    "    price_interval = 1000\n",
    "    \n",
    "    # Get min and max values (without £ and comma values)\n",
    "    min_price_value = int(min_price_box.get_attribute('value')[1:].replace(',', ''))\n",
    "    min_price_value = min_price_value - 1 # Minus 1, so we can add 1 in the loop\n",
    "    max_price_value = int(max_price_box.get_attribute('value')[1:].replace(',', ''))\n",
    "    # Find a neutral zone to click on\n",
    "    neutral = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[7]/div[1]/h3')\n",
    "    \n",
    "    total_freq = get_num_results()\n",
    "    cumul_freq = 0 # To cumulitively add the freqs as we go\n",
    "    \n",
    "    def bn_scrape_table():\n",
    "            bn_table = pd.DataFrame(columns = bn_headers)\n",
    "            table_web_source = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/section/div/div/div[2]')\n",
    "            table_html = BeautifulSoup(table_web_source.get_attribute('innerHTML'))\n",
    "            # Scrape the table! First get the raw table html\n",
    "            table_rows_html = table_html.find_all('a',{'class':'grid-row row '})\n",
    "            # Then loop through each row \n",
    "            for row in table_rows_html:\n",
    "                bn_data = []\n",
    "                # And loop through each value\n",
    "                for value in row.find_all('span'):\n",
    "                    bn_data.append(cleanhtml(str(value)))\n",
    "                bn_data = list(filter(('').__ne__, bn_data)) # Remove all empty values\n",
    "                del bn_data[4] # Delete index 4 in list as it returns two dupe vals - unique to their HTML\n",
    "                \n",
    "                bn_dict = dict(zip(bn_headers, bn_data))\n",
    "                bn_table = bn_table.append(bn_dict, ignore_index=True)\n",
    "            return(bn_table)\n",
    "    \n",
    "    # Loop through prices\n",
    "    for min_val in range(min_price_value, max_price_value, price_interval):\n",
    "        \n",
    "        lower_price = min_val + 1 # Add 1 so there are no overlapping intervals\n",
    "        higher_price = min_val + price_interval\n",
    "        \n",
    "        # Edit max price\n",
    "        max_price_box.click()\n",
    "        max_price_box.send_keys(Keys.BACKSPACE)\n",
    "        max_price_box.send_keys(str(higher_price)) \n",
    "        neutral.click()\n",
    "        time.sleep(random.uniform(0,1))\n",
    "        # Edit min price            \n",
    "        min_price_box.click()\n",
    "        min_price_box.send_keys(Keys.BACKSPACE)\n",
    "        min_price_box.send_keys(str(lower_price))\n",
    "        neutral.click()\n",
    "        time.sleep(random.uniform(1,3)) \n",
    "        \n",
    "        freq = get_num_results()\n",
    "        cumul_freq = cumul_freq + freq \n",
    "        \n",
    "        if (total_freq - cumul_freq) <= 999:\n",
    "            browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            pause_random(7,8) # Wait for the table to load\n",
    "            \n",
    "            bn_df = bn_df.append(bn_scrape_table(), ignore_index=True)\n",
    "            \n",
    "            # Edit max price\n",
    "            max_price_box.click()\n",
    "            max_price_box.send_keys(Keys.BACKSPACE)\n",
    "            max_price_box.send_keys(str(max_price_value)) \n",
    "            neutral.click()\n",
    "            time.sleep(random.uniform(0,1))\n",
    "            # Edit min price            \n",
    "            min_price_box.click()\n",
    "            min_price_box.send_keys(Keys.BACKSPACE)\n",
    "            min_price_box.send_keys(str(lower_price + price_interval))\n",
    "            neutral.click()\n",
    "            time.sleep(random.uniform(0,1))\n",
    "            \n",
    "            browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            pause_random(7,8) # Wait for the table to load\n",
    "            \n",
    "            bn_df = bn_df.append(bn_scrape_table(), ignore_index=True)\n",
    "            break \n",
    "        else:           \n",
    "            # If there are over 999 results, divide the interval into smaller\n",
    "            # intervals that approximately return 999 or less results for each.\n",
    "            if freq > 999:\n",
    "                sub_interval_number = freq / 999\n",
    "                sub_interval_price = round(price_interval / sub_interval_number)\n",
    "                \n",
    "                sub_min_price_value = lower_price - 1\n",
    "                sub_max_price_value = higher_price\n",
    "                \n",
    "                for min_val in range(sub_min_price_value, sub_max_price_value, sub_interval_price):\n",
    "                    \n",
    "                    sub_lower_price = min_val + 1 # Add 1 so there are no overlapping intervals\n",
    "                    sub_higher_price = min_val + sub_interval_price\n",
    "                    \n",
    "                    # Edit max price\n",
    "                    max_price_box.click()\n",
    "                    max_price_box.send_keys(Keys.BACKSPACE)\n",
    "                    max_price_box.send_keys(str(sub_higher_price)) \n",
    "                    neutral.click()\n",
    "                    time.sleep(random.uniform(0,1))\n",
    "                    # Edit min price            \n",
    "                    min_price_box.click()\n",
    "                    min_price_box.send_keys(Keys.BACKSPACE)\n",
    "                    min_price_box.send_keys(str(sub_lower_price))\n",
    "                    neutral.click()\n",
    "                    time.sleep(random.uniform(0,1))\n",
    "                    \n",
    "                    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    pause_random(7,8) # Wait for the table to load\n",
    "                    \n",
    "                    bn_df = bn_df.append(bn_scrape_table(), ignore_index=True)\n",
    "            \n",
    "    end = time.time()\n",
    "    print((end - start) / 60, 'mins to complete')\n",
    "    return(bn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.12620820204417 mins to complete\n"
     ]
    }
   ],
   "source": [
    "bn_df = get_bn_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_df.to_csv('blue_nile_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(173725, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shape</th>\n",
       "      <th>price</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>polish</th>\n",
       "      <th>symmetry</th>\n",
       "      <th>fluorescence</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>l/w</th>\n",
       "      <th>price/ct</th>\n",
       "      <th>culet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emerald</td>\n",
       "      <td>214.8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>Good</td>\n",
       "      <td>I</td>\n",
       "      <td>VS1</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>None</td>\n",
       "      <td>68.6</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.24</td>\n",
       "      <td>716.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pear</td>\n",
       "      <td>219.6</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Faint</td>\n",
       "      <td>61.8</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.51</td>\n",
       "      <td>708.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Princess</td>\n",
       "      <td>238.8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>None</td>\n",
       "      <td>73.4</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>955.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pear</td>\n",
       "      <td>248.4</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>G</td>\n",
       "      <td>SI2</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>None</td>\n",
       "      <td>62.2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>801.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pear</td>\n",
       "      <td>249.6</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>None</td>\n",
       "      <td>65.7</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>861.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      shape  price  carat        cut color clarity     polish   symmetry  \\\n",
       "0   Emerald  214.8   0.30       Good     I     VS1  Very Good  Very Good   \n",
       "1      Pear  219.6   0.31  Very Good     J     SI2  Very Good       Good   \n",
       "2  Princess  238.8   0.25  Very Good     D     SI1  Excellent  Very Good   \n",
       "3      Pear  248.4   0.31  Very Good     G     SI2       Good       Good   \n",
       "4      Pear  249.6   0.29  Very Good     E     SI2  Very Good       Good   \n",
       "\n",
       "  fluorescence  depth  table   l/w  price/ct culet  \n",
       "0         None   68.6   74.0  1.24     716.0  None  \n",
       "1        Faint   61.8   56.0  1.51     708.0  None  \n",
       "2         None   73.4   73.0  1.05     955.0  None  \n",
       "3         None   62.2   64.0  1.62     801.0  None  \n",
       "4         None   65.7   59.0  1.50     861.0  None  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bn_df.shape)\n",
    "bn_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "a8dae707-2c7a-4728-90dd-23e595076851"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
