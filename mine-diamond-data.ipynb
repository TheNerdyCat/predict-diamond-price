{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mine Diamond Data\n",
    "\n",
    "## Introduction\n",
    "In this notebook we will mine our data from as many sources as possible to prepare our dataset. We will target diamond merchants on the web, starting with Brilliant Earth (sorry Brilliant Earth... But thanks for the data).\n",
    "\n",
    "We'll start by importing our packages for scraping and regular expression, then quickly making a function to get the page content of a link. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_content(page_link):\n",
    "    page_response = requests.get(page_link, timeout=5)\n",
    "    page_content = BeautifulSoup(page_response.content)\n",
    "    return(page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "    \"\"\"\n",
    "    Remove HTML tags from string.\n",
    "    \"\"\"\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return(cleantext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blue Nile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For conciseness, Blue Nile we will denote as 'bn'\n",
    "bn_link = 'https://www.bluenile.com/uk/diamond-search'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bn_headers(page_content):\n",
    "    \"\"\"\n",
    "    Retrieves the headers for our Blue Nile dataframe\n",
    "    \"\"\"\n",
    "    headers_grid = page_content.find('div',{'class':'grid-header normal-header'})\n",
    "    headers_row = headers_grid.find('div', {'class':'row'})\n",
    "    \n",
    "    # Find all headers, and remove the tags from the string\n",
    "    headers_containers = []\n",
    "    for div in headers_row.find_all('div'):\n",
    "        headers_containers.append(cleanhtml(str(div.find('span'))))\n",
    "    \n",
    "    # Remove all 'None' string values from list\n",
    "    headers = list(filter(('None').__ne__, headers_containers))\n",
    "    headers.remove('Compare')\n",
    "    \n",
    "    return(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_page_content = get_page_content(bn_link)\n",
    "bn_headers = get_bn_headers(bn_page_content)\n",
    "print(bn_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome('C:/Users/Edward Sims/Downloads/chromedriver.exe')\n",
    "browser.get('https://www.bluenile.com/uk/diamond-search?track=NavDiaSea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncheck the 360 view option for more data\n",
    "view_checkbox = browser.find_element_by_class_name('bn-checkbox')\n",
    "view_checkbox.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# Open more filters\n",
    "more_filters = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[13]')\n",
    "more_filters.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# Open polish option\n",
    "polish_add = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[12]/div[1]/div[1]/div/div/div')\n",
    "polish_add.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# Open symmetry option\n",
    "symmetry_add = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[12]/div[2]/div[1]/div/div/div')\n",
    "symmetry_add.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# Open fluorescence option\n",
    "fluorescence_add = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[12]/div[3]/div[1]/div/div')\n",
    "fluorescence_add.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# Open depth % option\n",
    "depth_add = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[12]/div[4]/div[1]/div/div')\n",
    "depth_add.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# Open table % option\n",
    "table_add = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[12]/div[5]/div[1]/div/div')\n",
    "table_add.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# Open L/W Ratio option\n",
    "lw_add = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[12]/div[6]/div[1]/div/div')\n",
    "lw_add.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# Add culet column\n",
    "culet_add = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[12]/div[8]/div[2]/button')\n",
    "culet_add.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "princess_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[2]/div[3]')\n",
    "emerald_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[3]/div[3]')\n",
    "asscher_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[4]/div[3]')\n",
    "cushion_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[5]/div[3]')\n",
    "marquise_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[6]/div[3]')\n",
    "radiant_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[7]/div[3]')\n",
    "oval_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[8]/div[3]')\n",
    "pear_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[9]/div[3]')\n",
    "heart_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[10]/div[3]')\n",
    "\n",
    "princess_details.click()\n",
    "time.sleep(0.5)\n",
    "emerald_details.click()\n",
    "time.sleep(1)\n",
    "asscher_details.click()\n",
    "time.sleep(1)\n",
    "cushion_details.click()\n",
    "time.sleep(0.5)\n",
    "marquise_details.click()\n",
    "time.sleep(0.5)\n",
    "radiant_details.click()\n",
    "time.sleep(1)\n",
    "oval_details.click()\n",
    "time.sleep(0.5)\n",
    "pear_details.click()\n",
    "time.sleep(1)\n",
    "heart_details.click()\n",
    "time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bn_data():\n",
    "    \"\"\"\n",
    "    Loops through all the price values in tens, scrapes\n",
    "    \"\"\"\n",
    "    bn_data = []\n",
    "    bn_headers = []\n",
    "\n",
    "    # Get the headers for our table\n",
    "    headers_data = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/section/div/div/div[1]/div')\n",
    "    headers_html = BeautifulSoup(headers_data.get_attribute('innerHTML'))\n",
    "    \n",
    "    for div in headers_html.find_all('div'):\n",
    "        for header in div.find_all('span'):\n",
    "            bn_headers.append(cleanhtml(str(header)))\n",
    "    bn_headers = list(filter(('').__ne__, bn_headers))\n",
    "    bn_headers.remove('Compare')\n",
    "    \n",
    "    \n",
    "    min_price = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[7]/div[2]/div/div[1]/input[1]')\n",
    "    max_price = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[7]/div[2]/div/div[1]/input[2]')\n",
    "\n",
    "    # Get the min and max values (minus Â£ and comma values)\n",
    "    min_price_value = int(min_price.get_attribute('value')[1:].replace(',', ''))\n",
    "    max_price_value = int(max_price.get_attribute('value')[1:].replace(',', ''))\n",
    "    \n",
    "    # Find a neutral zone to click on\n",
    "    neutral = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[7]/div[1]/h3')\n",
    "    \n",
    "    # Loop through prices to limit numbers displayed - ISSUE WITH DUPES/OVERLAPS?   \n",
    "    for min_val in range(min_price_value, 201, 10):\n",
    "        \n",
    "        # Edit min price\n",
    "        min_price.click()\n",
    "        min_price.send_keys(Keys.BACKSPACE)\n",
    "        time.sleep(1)\n",
    "        min_price.send_keys(str(min_val))\n",
    "        neutral.click()\n",
    "        time.sleep(2.4)\n",
    "        \n",
    "        # Edit max price\n",
    "        max_price.click()\n",
    "        max_price.send_keys(Keys.BACKSPACE)\n",
    "        time.sleep(2)\n",
    "        max_price.send_keys(str(min_val+10))\n",
    "        neutral.click()\n",
    "        time.sleep(2.2)\n",
    "        \n",
    "        # Scrape the table! First get the raw table html\n",
    "        for a in browser.find_elements_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/section/div/div/div[2]'):\n",
    "            table_web_source = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/section/div/div/div[2]')\n",
    "            table_html = BeautifulSoup(table_web_source.get_attribute('innerHTML'))\n",
    "            table_rows_html = table_html.find_all('a',{'class':'grid-row row '})\n",
    "            time.sleep(1.8)\n",
    "            \n",
    "            # Loop through each row \n",
    "            for row in table_rows_html:\n",
    "                \n",
    "                # Loop through each value and store in list\n",
    "                for value in row.find_all('span'):\n",
    "                    bn_data.append(cleanhtml(str(value)))\n",
    "        bn_data = list(filter(('').__ne__, bn_data)) # Remove all empty values\n",
    "        #print(bn_data)\n",
    "        \n",
    "        bn_data_list = [i for j, i in enumerate(bn_data) if (j+1) %5 ]\n",
    "\n",
    "    def split_list(x):\n",
    "        return([bn_data_list[i:i+x] for i in range(0, len(bn_data_list), x)])\n",
    "    \n",
    "    # Chunk out the list to fit to a dataframe\n",
    "    #bn_data_list = split_list(len(bn_headers))\n",
    "    \n",
    "    #bn_df = pd.DataFrame.from_records(bn_data_list, columns = bn_headers)\n",
    "    \n",
    "    return(bn_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shape',\n",
       " 'Price',\n",
       " 'Carat',\n",
       " 'Cut',\n",
       " 'Color',\n",
       " 'Clarity',\n",
       " 'Polish',\n",
       " 'Symmetry',\n",
       " 'Fluorescence',\n",
       " 'Depth',\n",
       " 'Table',\n",
       " 'L/W',\n",
       " 'Price/Ct',\n",
       " 'Culet',\n",
       " 'Stock No.',\n",
       " 'Dispatch Date']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bn_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ['Pear',\n",
    " 'Â£171.60',\n",
    " '0.24',\n",
    " 'Very Good',\n",
    " 'F',\n",
    " 'SI1',\n",
    " 'Good',\n",
    " 'Good',\n",
    " '64.6',\n",
    " '55.0',\n",
    " '1.57',\n",
    " 'Â£715',\n",
    " 'LD12004073',\n",
    " 'Jun 13',\n",
    " 'Princess',\n",
    " 'Â£193.20',\n",
    " 'Very Good',\n",
    " 'Very Good',\n",
    " 'G',\n",
    " 'SI1',\n",
    " 'Good',\n",
    " 'None',\n",
    " '75.0',\n",
    " '71.0',\n",
    " 'Â£840',\n",
    " 'None',\n",
    " 'LD12437282',\n",
    " 'Jun 13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['Shape',\n",
    " 'Price',\n",
    " 'Carat',\n",
    " 'Cut',\n",
    " 'Color',\n",
    " 'Clarity',\n",
    " 'Polish',\n",
    " 'Symmetry',\n",
    " 'Fluorescence',\n",
    " 'Depth',\n",
    " 'Table',\n",
    " 'L/W',\n",
    " 'Price/Ct',\n",
    " 'Culet',\n",
    " 'Stock No.',\n",
    " 'Dispatch Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pear',\n",
       " 'Â£171.60',\n",
       " '0.24',\n",
       " 'Very Good',\n",
       " 'F',\n",
       " 'SI1',\n",
       " 'Good',\n",
       " 'Good',\n",
       " '64.6',\n",
       " '55.0',\n",
       " '1.57',\n",
       " 'Â£715',\n",
       " 'LD12004073',\n",
       " 'Jun 13',\n",
       " 'Princess',\n",
       " 'Â£193.20',\n",
       " 'Very Good',\n",
       " 'Very Good',\n",
       " 'G',\n",
       " 'SI1',\n",
       " 'Good',\n",
       " 'None',\n",
       " '75.0',\n",
       " '71.0',\n",
       " 'Â£840',\n",
       " 'None',\n",
       " 'LD12437282',\n",
       " 'Jun 13']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ['Pear','Â£171.60','0.24','Very Good','Very Good','F','SI1','Good','Good','None','64.6','55.0','1.57','Â£715','None','LD12004073']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pear',\n",
       " 'Â£171.60',\n",
       " '0.24',\n",
       " 'Very Good',\n",
       " 'F',\n",
       " 'SI1',\n",
       " 'Good',\n",
       " 'Good',\n",
       " '64.6',\n",
       " '55.0',\n",
       " '1.57',\n",
       " 'Â£715',\n",
       " 'LD12004073']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for j, i in enumerate(df) if (j+1) %5 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "a8dae707-2c7a-4728-90dd-23e595076851"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
