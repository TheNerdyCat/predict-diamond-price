{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Mining Diamond Data - Blue Nile®\n",
    "\n",
    "## (a) Introduction\n",
    "In this series of notebooks we are mining diamond data from as many sources as possible to prepare our dataset. Ultimately, we want to be doing some Machine Learning on these data - but the sccraping is just as fun! We are targeting diamond merchants on the web, starting with Blue Nile® (soz Blue Nile®... but thx for the data). \n",
    "\n",
    "In all seriousness, this data is the property of Blue Nile®, so please be respectful. I try and stick to web scraping best practises in these scripts, so if you are going to use it, please keep these in. They mostly revolve around slowing the functions down, which I realise may be frustrating, but let's keep up the standards.\n",
    "\n",
    "We'll start by importing our usual packages, packages for scraping and regular expression as well as some ad hoc ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Import packages / define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "import time # To help with slowing our functions down\n",
    "import random # To assign random floats to breaks, hiding predictable patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_content(page_link):\n",
    "    \"\"\"\n",
    "    Scrape the targeted HTML and store as a bs object\n",
    "    \"\"\"\n",
    "    page_response = requests.get(page_link, timeout=5)\n",
    "    page_content = BeautifulSoup(page_response.content)\n",
    "    return(page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "    \"\"\"\n",
    "    Remove HTML tags from string.\n",
    "    \"\"\"\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return(cleantext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Mine Blue Nile® dataset\n",
    "\n",
    "For reference, I denote Blue Nile® as `bn` for short.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For conciseness, Blue Nile we will denote as 'bn'\n",
    "bn_link = 'https://www.bluenile.com/uk/diamond-search'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bn_headers(page_content):\n",
    "    \"\"\"\n",
    "    Retrieves the headers for our Blue Nile dataframe\n",
    "    \"\"\"\n",
    "    headers_grid = page_content.find('div',{'class':'grid-header normal-header'})\n",
    "    headers_row = headers_grid.find('div', {'class':'row'})\n",
    "    \n",
    "    # Find all headers, and remove the tags from the string\n",
    "    headers_containers = []\n",
    "    for div in headers_row.find_all('div'):\n",
    "        headers_containers.append(cleanhtml(str(div.find('span'))))\n",
    "    \n",
    "    # Remove all 'None' string values from list\n",
    "    headers = list(filter(('None').__ne__, headers_containers))\n",
    "    headers.remove('Compare')\n",
    "    \n",
    "    return(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome('C:/Users/Edward Sims/Downloads/chromedriver.exe')\n",
    "browser.get('https://www.bluenile.com/uk/diamond-search?track=NavDiaSea')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have to manually remove the cookie notice... I haven't got a working solution just yet. Any tips, I'm all ears!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncheck the 360 view option for more data\n",
    "view_checkbox = browser.find_element_by_class_name('bn-checkbox')\n",
    "view_checkbox.click()\n",
    "time.sleep(random.uniform(0.3,3))\n",
    "\n",
    "# Open more filters\n",
    "more_filters = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[13]')\n",
    "more_filters.click()\n",
    "time.sleep(random.uniform(0.3,3))\n",
    "\n",
    "# Open polish option\n",
    "polish_add = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[12]/div[1]/div[1]/div/div/div')\n",
    "polish_add.click()\n",
    "time.sleep(random.uniform(0.3,3))\n",
    "\n",
    "# Open symmetry option\n",
    "symmetry_add = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[12]/div[2]/div[1]/div/div/div')\n",
    "symmetry_add.click()\n",
    "time.sleep(random.uniform(0.3,3))\n",
    "\n",
    "# Open fluorescence option\n",
    "fluorescence_add = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[12]/div[3]/div[1]/div/div')\n",
    "fluorescence_add.click()\n",
    "time.sleep(random.uniform(0.3,3))\n",
    "\n",
    "# Open depth % option\n",
    "depth_add = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[12]/div[4]/div[1]/div/div')\n",
    "depth_add.click()\n",
    "time.sleep(random.uniform(0.3,3))\n",
    "\n",
    "# Open table % option\n",
    "table_add = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[12]/div[5]/div[1]/div/div')\n",
    "table_add.click()\n",
    "time.sleep(random.uniform(0.3,3))\n",
    "\n",
    "# Open L/W Ratio option\n",
    "lw_add = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[12]/div[6]/div[1]/div/div')\n",
    "lw_add.click()\n",
    "time.sleep(random.uniform(0.3,3))\n",
    "\n",
    "# Add culet column\n",
    "culet_add = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[12]/div[8]/div[2]/button')\n",
    "culet_add.click()\n",
    "time.sleep(random.uniform(0.3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "princess_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[2]/div[3]')\n",
    "emerald_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[3]/div[3]')\n",
    "asscher_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[4]/div[3]')\n",
    "cushion_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[5]/div[3]')\n",
    "marquise_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[6]/div[3]')\n",
    "radiant_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[7]/div[3]')\n",
    "oval_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[8]/div[3]')\n",
    "pear_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[9]/div[3]')\n",
    "heart_details = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[6]/div[2]/div/div[10]/div[3]')\n",
    "\n",
    "princess_details.click()\n",
    "time.sleep(random.uniform(0.3,3))\n",
    "emerald_details.click()\n",
    "time.sleep(random.uniform(0.3,3))\n",
    "asscher_details.click()\n",
    "time.sleep(random.uniform(0.3,3))\n",
    "cushion_details.click()\n",
    "time.sleep(random.uniform(0.3,3))\n",
    "marquise_details.click()\n",
    "time.sleep(random.uniform(0.3,3))\n",
    "radiant_details.click()\n",
    "time.sleep(random.uniform(0.3,3))\n",
    "oval_details.click()\n",
    "time.sleep(random.uniform(0.3,3))\n",
    "pear_details.click()\n",
    "time.sleep(random.uniform(0.3,3))\n",
    "heart_details.click()\n",
    "time.sleep(random.uniform(0.3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difficulty with scraping the table is that a maximum of 1000 results are displayed. And the prices of diamonds are hugely skewed around the £600-£2,000 price range. Now we could just increase the price range by a small amount, say, £10 at a time, but given that the maximum price is over a million, this will end up taking FOREVER. But what's more, is that even in that price range there are still sometimes too many records for the table to display. And even worse still, because the data are so skewed, we'll be looping through prices at the higher end and there will not even be anything in there to display. So basically a massive waste of time for everybody involved.\n",
    "\n",
    "What we'll do instead is do a bit of exploration first. Let's gather some rough frequency data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_price_freqs():\n",
    "    \"\"\"\n",
    "    Loops through price, scrapes and stores the \n",
    "    number of results at each range.\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_num_results():\n",
    "        \"\"\"\n",
    "        Scrapes the number of results shown in the price range.    \n",
    "        \"\"\"\n",
    "        results_path = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[2]/div[4]/button[1]/span[2]')\n",
    "        # Scrape the HTML and clean\n",
    "        results_val = cleanhtml(str(BeautifulSoup(results_path.get_attribute('innerHTML'))))\n",
    "        # Strip the punctuation, and convert to integer\n",
    "        results_val = int(re.sub(r'[^\\w\\s]','', results_val))\n",
    "        return(results_val)\n",
    "\n",
    "    # Create a dataframe with our new headers\n",
    "    headers = ['price_range','freq']\n",
    "    bn_price_freq = pd.DataFrame(columns=headers)\n",
    "    \n",
    "    # Min and max price locations\n",
    "    min_price = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[7]/div[2]/div/div[1]/input[1]')\n",
    "    max_price = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[7]/div[2]/div/div[1]/input[2]')\n",
    "    \n",
    "    # Assign a default interval value\n",
    "    price_interval = 2000\n",
    "    \n",
    "    # Get the min and max values (without £ and comma values)\n",
    "    min_price_value = int(min_price.get_attribute('value')[1:].replace(',', ''))\n",
    "    max_price_value = int(max_price.get_attribute('value')[1:].replace(',', ''))\n",
    "    \n",
    "    # Find a neutral zone to click on\n",
    "    neutral = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[7]/div[1]/h3')\n",
    "    \n",
    "    # Loop through prices to limit numbers displayed\n",
    "    for min_val in range(min_price_value, 6000, price_interval):\n",
    "        \n",
    "        \n",
    "        \n",
    "        if min_price_value == min_val:\n",
    "            # Edit min price\n",
    "            min_price.click()\n",
    "            min_price.send_keys(Keys.BACKSPACE)\n",
    "            time.sleep(1)\n",
    "            min_price.send_keys(str(min_val))\n",
    "            neutral.click()\n",
    "            time.sleep(random.uniform(0.3,3))\n",
    "        else:\n",
    "            # Edit min price            \n",
    "            min_price.click()\n",
    "            min_price.send_keys(Keys.BACKSPACE)\n",
    "            time.sleep(1)\n",
    "            min_price.send_keys(str(min_val))\n",
    "            neutral.click()\n",
    "            time.sleep(random.uniform(0.3,3))            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        # Edit max price\n",
    "        max_price.click()\n",
    "        max_price.send_keys(Keys.BACKSPACE)\n",
    "        time.sleep(2)\n",
    "        max_price.send_keys(str(min_val+price_interval)) \n",
    "        neutral.click()\n",
    "        time.sleep(random.uniform(0.3,4))\n",
    "        \n",
    "        # Get the current ranges\n",
    "        lower_price = int(min_price.get_attribute('value')[1:].replace(',', ''))+1\n",
    "        higher_price = int(max_price.get_attribute('value')[1:].replace(',', ''))\n",
    "        \n",
    "        # Collect the freq data \n",
    "        price_range = str(lower_price) + ' to ' + str(higher_price)\n",
    "        freq = get_num_results()\n",
    "        results = [price_range, freq]\n",
    "        \n",
    "        bn_price_freq = bn_price_freq.append(dict(zip(headers,results)),ignore_index=True)\n",
    "\n",
    "    print(max_price_value)\n",
    "    return(bn_price_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1556733\n"
     ]
    }
   ],
   "source": [
    "# Collect the frequencies and remove all ranges with no results\n",
    "bn_price_freqs = collect_price_freqs()\n",
    "#bn_price_freqs_no_zero = bn_price_freqs[bn_price_freqs.freq != 0].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_range</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203 to 2202</td>\n",
       "      <td>137083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2203 to 4202</td>\n",
       "      <td>23375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4203 to 6202</td>\n",
       "      <td>15922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price_range    freq\n",
       "0   203 to 2202  137083\n",
       "1  2203 to 4202   23375\n",
       "2  4203 to 6202   15922"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_price_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_price_freqs_no_zero.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = list(bn_price_freqs_no_zero.freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bn_data():\n",
    "    \"\"\"\n",
    "    Loops through all the price values, scrapes the results and stores\n",
    "    it into a dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    bn_headers = []\n",
    "    \n",
    "    # Isolate the table headers HTML\n",
    "    headers_data = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/section/div/div/div[1]/div')\n",
    "    headers_html = BeautifulSoup(headers_data.get_attribute('innerHTML'))\n",
    "    \n",
    "    # Get the header values\n",
    "    for div in headers_html.find_all('div'):\n",
    "        for header in div.find_all('span'):\n",
    "            bn_headers.append(cleanhtml(str(header)))\n",
    "    bn_headers = list(filter(('').__ne__, bn_headers))\n",
    "    bn_headers.remove('Compare')\n",
    "    \n",
    "    # Create a dataframe with our new headers\n",
    "    bn_df = pd.DataFrame(columns=bn_headers)\n",
    "    \n",
    "    # Min and max price locations\n",
    "    min_price = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[7]/div[2]/div/div[1]/input[1]')\n",
    "    max_price = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[7]/div[2]/div/div[1]/input[2]')\n",
    "    \n",
    "    # Assign a default range value\n",
    "    price_range = 10\n",
    "    \n",
    "    # Get the min and max values (without £ and comma values)\n",
    "    min_price_value = int(min_price.get_attribute('value')[1:].replace(',', ''))\n",
    "    max_price_value = int(max_price.get_attribute('value')[1:].replace(',', ''))\n",
    "    \n",
    "    # Find a neutral zone to click on\n",
    "    neutral = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/div[1]/div[2]/div[3]/div[7]/div[1]/h3')\n",
    "    \n",
    "    # Loop through prices to limit numbers displayed\n",
    "    for min_val in range(min_price_value, 237, price_range):\n",
    "        \n",
    "        # Edit min price\n",
    "        min_price.click()\n",
    "        min_price.send_keys(Keys.BACKSPACE)\n",
    "        time.sleep(1)\n",
    "        min_price.send_keys(str(min_val))\n",
    "        neutral.click()\n",
    "        time.sleep(random.uniform(0.3,3))\n",
    "        \n",
    "        # Edit max price\n",
    "        max_price.click()\n",
    "        max_price.send_keys(Keys.BACKSPACE)\n",
    "        time.sleep(2)\n",
    "        max_price.send_keys(str(min_val+price_range)) \n",
    "        neutral.click()\n",
    "\n",
    "        time.sleep(random.uniform(0.3,4))\n",
    "        \n",
    "        table_web_source = browser.find_element_by_xpath('//*[@id=\"react-app\"]/div/div/div/section[1]/section/div/div/div[2]')\n",
    "        table_html = BeautifulSoup(table_web_source.get_attribute('innerHTML'))\n",
    "        \n",
    "        # Scrape the table! First get the raw table html\n",
    "        table_rows_html = table_html.find_all('a',{'class':'grid-row row '})\n",
    "        time.sleep(random.uniform(0.3,10))\n",
    "            \n",
    "        # Then loop through each row \n",
    "        for row in table_rows_html:\n",
    "            bn_data = []\n",
    "            # And loop through each value\n",
    "            for value in row.find_all('span'):\n",
    "                bn_data.append(cleanhtml(str(value)))\n",
    "            \n",
    "            bn_data = list(filter(('').__ne__, bn_data)) # Remove all empty values\n",
    "            del bn_data[4] # Delete index 4 in list as it returns two dupe vals - unique to their HTML\n",
    "            #print(bn_data)\n",
    "            bn_df = bn_df.append(dict(zip(bn_headers,bn_data)),ignore_index=True)\n",
    "\n",
    "    \n",
    "        return(bn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bn_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_val > 999: \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_price_value = int(min_price.get_attribute('value')[1:].replace(',', ''))\n",
    "max_price_value = int(max_price.get_attribute('value')[1:].replace(',', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "a8dae707-2c7a-4728-90dd-23e595076851"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
