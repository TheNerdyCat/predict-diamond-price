{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "Later I'll compile all the other datasets and create notebooks for the EDA, engineering, HP tuning, modelling etc. But for now, we'll just make a blended regression model for just our Blue Nile data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "plt.rcParams['figure.figsize'] = [12, 7]\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_df = pd.read_csv('input/blue_nile_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert currency features to floats\n",
    "bn_df['Price'] = bn_df['Price'].replace('[\\£,]', '', regex=True).astype(float)\n",
    "bn_df['Price/Ct'] = bn_df['Price/Ct'].replace('[\\£,]', '', regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(bn_df['Price'].iloc[0:170000], hist=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't need the `Dispatch Date` and `Stock No`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_df = bn_df.drop(['Stock No.', 'Dispatch Date'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.scatter_matrix(bn_df, alpha=0.2, figsize=(10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_df_categorical = bn_df.select_dtypes(include='object')\n",
    "bn_df_numerical = bn_df.select_dtypes(include='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(8,1,figsize = (8,20))\n",
    "fig.tight_layout()\n",
    "for i, feature in enumerate(bn_df_categorical.columns):\n",
    "    plot = sns.countplot(bn_df_categorical[feature], color='teal', ax=ax[i], )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll remove the `culet` feature do to a the low variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_df = bn_df.drop('Culet', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to decide what to do with the categorical features - whether to one-hot encode them or map them top some kind of ordinal number. Turns out there are pretty clear scales for all features except fluorescence. We'll one-hot encode this, along with shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut\n",
    "cut_scale_dict = dict(zip(bn_df['Cut'].unique(), [0,1,2,3]))\n",
    "# Color\n",
    "color_scale_dict = dict(zip(sorted(bn_df['Color'].unique()), range(0,len(bn_df['Color'].unique()))))\n",
    "# Clarity - had to do some research for this\n",
    "clarity_scale_dict = dict(zip(bn_df['Clarity'].unique(), [3,6,5,2,4,1,0,0]))\n",
    "# Polish\n",
    "polish_scale_dict = dict(zip(bn_df['Polish'].unique(), [1,2,0]))\n",
    "# Symmetry\n",
    "symmetry_scale_dict = dict(zip(bn_df['Symmetry'].unique(), [1,0,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_df = bn_df.replace({'Cut': cut_scale_dict})\n",
    "bn_df = bn_df.replace({'Color': color_scale_dict})\n",
    "bn_df = bn_df.replace({'Clarity': clarity_scale_dict})\n",
    "bn_df = bn_df.replace({'Polish': polish_scale_dict})\n",
    "bn_df = bn_df.replace({'Symmetry': symmetry_scale_dict})\n",
    "bn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower case all values and replace white spaces with underscores\n",
    "bn_df['Shape'] = bn_df['Shape'].str.lower()\n",
    "\n",
    "bn_df['Fluorescence'] = bn_df['Fluorescence'].str.lower()\n",
    "bn_df['Fluorescence'] = bn_df['Fluorescence'].replace(' ', '_', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummies(df, columns):\n",
    "    for column in columns:\n",
    "        df[column] = df[column].apply(lambda x: str(x))\n",
    "        df = pd.concat((df, pd.get_dummies(df[column], prefix = column)), axis = 1)\n",
    "        df = df.drop(column, 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_df_final = dummies(bn_df, ['Shape', 'Fluorescence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the high variance, we'll log our price value\n",
    "bn_df_final['Price'] = np.log1p(bn_df_final[\"Price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bn_df_final.loc[:, bn_df_final.columns != 'Price']\n",
    "y = bn_df_final['Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit = []\n",
    "for i in X.columns:\n",
    "    counts = X[i].value_counts()\n",
    "    zeros = counts.iloc[0]\n",
    "    if zeros / len(X) * 100 > 99.94:\n",
    "        overfit.append(i)\n",
    "\n",
    "overfit = list(overfit)\n",
    "print(overfit)\n",
    "X = X.drop(overfit, axis=1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds = KFold(n_splits=10, shuffle=True, random_state=21)\n",
    "\n",
    "def rmsle(y, y_pred):\n",
    "    \"\"\"\n",
    "    Return root mean squared logarithmic error\n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def cv_rmse(model, X=X):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=kfolds))\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=alphas_alt, cv=kfolds))\n",
    "\n",
    "lasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas=alphas2, random_state=42, cv=kfolds))\n",
    "\n",
    "elasticnet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio))\n",
    "\n",
    "svr = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(n_estimators=1000, \n",
    "                                learning_rate=0.05, \n",
    "                                max_depth=4, \n",
    "                                max_features='auto', \n",
    "                                min_samples_leaf=15, \n",
    "                                min_samples_split=10, \n",
    "                                loss='huber')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm = LGBMRegressor(objective='regression', \n",
    "                         num_leaves=4,\n",
    "                         n_estimators=1000,\n",
    "                         learning_rate=0.01, \n",
    "                         max_bin=200, \n",
    "                         bagging_fraction=0.75,\n",
    "                         bagging_freq=5, \n",
    "                         bagging_seed=7,\n",
    "                         feature_fraction=0.2,\n",
    "                         feature_fraction_seed=7,\n",
    "                         verbose=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = XGBRegressor(learning_rate=0.01,\n",
    "                       n_estimators=1000,     \n",
    "                       max_depth=3, \n",
    "                       min_child_weight=0,\n",
    "                       gamma=0, \n",
    "                       subsample=0.7,\n",
    "                       colsample_bytree=0.7,\n",
    "                       objective='reg:linear', \n",
    "                       scale_pos_weight=1,\n",
    "                       n_jobs=-1,\n",
    "                       reg_alpha=0.00006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_gen = StackingCVRegressor(regressors=(ridge, lasso, elasticnet, gbr, xgboost, lightgbm),\n",
    "                                meta_regressor=xgboost,\n",
    "                                use_features_in_secondary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cv_rmse(ridge)\n",
    "score = cv_rmse(lasso)\n",
    "print(\"LASSO: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.datetime.now(), )\n",
    "\n",
    "score = cv_rmse(elasticnet)\n",
    "print(\"elastic net: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.datetime.now(), )\n",
    "\n",
    "score = cv_rmse(svr)\n",
    "print(\"SVR: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.datetime.now(), )\n",
    "\n",
    "score = cv_rmse(lightgbm)\n",
    "print(\"lightgbm: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.datetime.now(), )\n",
    "\n",
    "score = cv_rmse(gbr)\n",
    "print(\"gbr: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.datetime.now(), )\n",
    "\n",
    "score = cv_rmse(xgboost)\n",
    "print(\"xgboost: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.datetime.now(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start Fit')\n",
    "\n",
    "print('stack_gen')\n",
    "stack_gen_model = stack_gen.fit(np.array(X_train), np.array(y_train))\n",
    "\n",
    "print('elasticnet')\n",
    "elastic_model_full_data = elasticnet.fit(X_train, y_train)\n",
    "\n",
    "print('Lasso')\n",
    "lasso_model_full_data = lasso.fit(X_train, y_train)\n",
    "\n",
    "print('Ridge')\n",
    "ridge_model_full_data = ridge.fit(X_train, y_train)\n",
    "\n",
    "print('Svr')\n",
    "svr_model_full_data = svr.fit(X_train, y_train)\n",
    "\n",
    "print('GradientBoosting')\n",
    "gbr_model_full_data = gbr.fit(X_train, y_train)\n",
    "\n",
    "print('xgboost')\n",
    "xgb_model_full_data = xgboost.fit(X_train, y_train)\n",
    "\n",
    "print('lightgbm')\n",
    "lgb_model_full_data = lightgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_models_predict(X):\n",
    "    return ((0.1 * elastic_model_full_data.predict(X)) + \\\n",
    "            (0.05 * lasso_model_full_data.predict(X)) + \\\n",
    "            (0.1 * ridge_model_full_data.predict(X)) + \\\n",
    "            (0.1 * svr_model_full_data.predict(X)) + \\\n",
    "            (0.15 * gbr_model_full_data.predict(X)) + \\\n",
    "            (0.1 * xgb_model_full_data.predict(X)) + \\\n",
    "            (0.1 * lgb_model_full_data.predict(X)) + \\\n",
    "            (0.3 * stack_gen_model.predict(np.array(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y_train, blend_models_predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RMSLE score on test data:')\n",
    "print(rmsle(y_test, blend_models_predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "a8dae707-2c7a-4728-90dd-23e595076851"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
